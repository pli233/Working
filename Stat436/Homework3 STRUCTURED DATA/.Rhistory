scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot")
)
server <- function(input, output) {
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
}
shinyApp(ui, server)
library(shiny)
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot")
)
server <- function(input, output) {
#Answer of question a starts here:
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
}
shinyApp(ui, server)
library(shiny)
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot")
)
server <- function(input, output) {
#Answer of question a starts here:
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
}
shinyApp(ui, server)
library(shiny)
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot"),
dataTableOutput("table")
)
server <- function(input, output) {
#Answer of question a starts here:
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
# Render the data table for selected athletes
output$table <- renderDataTable({
filtered_data() %>%
filter(selected == TRUE) %>%
select(Name, Sport, `Height, cm`, Weight)
})
}
shinyApp(ui, server)
# Chunk 1
#Hide unnecessary output and warning message such as library(tidyverse)
knitr::opts_chunk$set(warnings = FALSE, message = FALSE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(sf)
library(raster)
library(tmap)
# Chunk 2
bike_data <- read_csv("https://uwmadison.box.com/shared/static/f16jmkkskylfl1hnd5rpslzduja929g2.csv")
head(bike_data)
# Chunk 3
#Select required data and rename them properly
q1 <- bike_data %>%
dplyr::select(weekday, hr, count) %>%
mutate(weekday = factor(weekday, levels = 0:6, labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>%
group_by(hr, weekday) %>%
summarise(summary = sum(count))
# Plotting with geom_line
ggplot(q1, aes(x = hr, y = summary)) + # Ensure that we group by weekday for the line plot
geom_line(aes(color = weekday)) +
facet_wrap(~weekday) + # Facets for each weekday
labs(x = "Hour of the Day", y = "Count of Bike Rentals", title = "Bike Demand by Hour Across the Week") +
theme_minimal()+
theme(plot.title = element_text(hjust = 0.5)) # Center the title
# Chunk 4
q2 <- bike_data %>%
mutate(yr = yr + 2011) %>%
mutate(weekday = factor(weekday, levels = 0:6, labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>%
group_by(yr, weekday, hr) %>%
summarise(
Q25 = quantile(count, 0.25),
Q75 = quantile(count, 0.75)
) %>%
rename(year = yr, hour = hr) # Renaming the columns
q2
# Chunk 5
# Merge the summary data with the quantile data.
# Since q2 contains summaries for each year, we will need to join this with q1 based on hr and weekday.
# Assuming that q1 has been grouped and summarised without the year, we will need to account for this.
# First, let's correct the renaming issue in the q2 data frame:
q1 <- q1 %>%
rename(hour = hr) # Rename hr to hour
# Now let's merge q1 and q2
q3 <- q1 %>%
ungroup() %>% # Make sure q1 is not grouped
left_join(q2, by = c("weekday", "hour")) # Join q2 data to q1 data
# Plotting with geom_ribbon and geom_line
ggplot(q3, aes(x = hour, y = summary)) +
geom_ribbon(aes(ymin = Q25, ymax = Q75, fill = as.factor(year)), alpha = 0.8) +
geom_line(aes(color = weekday)) +
facet_wrap(~weekday) + # Facets for each weekday
scale_fill_manual(values = c("blue", "red"), name = "Year") + # Set manual colors for the ribbon based on year
labs(x = "Hour of the Day", y = "Count of Bike Rentals", title = "Bike Demand by Hour Across the Week") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5)) # Center the title and move legend to bottom
# Chunk 6
nyc_sf <-read_sf("https://uwmadison.box.com/shared/static/qfmrp9srsoq0a7oj0e7xmgu5spojr33e.geojson")
nyc_sf %>%dplyr::select(geometry)
# Chunk 7
africa_pop <- raster("https://github.com/krisrs1128/stat436_s24/raw/main/data/afripop2020.tif")
africa_pop
# Chunk 8
himalayan_lakes <- read_sf("https://raw.githubusercontent.com/krisrs1128/stat436_s23/main/data/GL_3basins_2015.topojson")
himalayan_lakes %>% dplyr::select(geometry)
# Chunk 9
wi_ev_charging <- read_sf("https://raw.githubusercontent.com/krisrs1128/stat436_s24/main/data/ev.geojson")
wi_ev_charging %>% dplyr::select(geometry)
# Chunk 10
zion_evl <- raster("https://github.com/krisrs1128/stat436_s24/raw/main/data/landsat.tif")
zion_evl
# Chunk 11
tm_shape(zion_evl) +
tm_raster()
# Chunk 12
library(tidygraph)
edge_data_path <- "https://raw.githubusercontent.com/krisrs1128/stat992_f23/6c4130bddbdfc9ef90537c794cdca47773643752/activities/week10/political-books-edges.csv"
node_data_path <- "https://github.com/krisrs1128/stat992_f23/raw/6c4130bddbdfc9ef90537c794cdca47773643752/activities/week10/political-books-nodes.csv"
edges <- read_csv(edge_data_path, col_types = "cci")
nodes <- read_csv(node_data_path, col_types = "ccc")
# Building the tbl_graph
book_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)
book_graph
# Chunk 13
library(ggraph)
ggraph(book_graph, layout = "kk") +
geom_edge_link(width = 0.1) +
geom_node_point(aes(color = political_ideology))+
geom_node_label(aes(label = label), size = 1.1, repel = TRUE)
# Chunk 14
ggraph(book_graph, "matrix") +
geom_edge_tile(mirror = TRUE) + #its not directed so mirror, its ok not mirror as well
coord_fixed() #make sure grid are square
# Chunk 15
stressor <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/stressor.csv') %>%
mutate(stress_pct = replace_na(stress_pct, 0))
# Reshape the data to have stressor types as columns
stressor_wide <- stressor %>%
pivot_wider(
names_from = stressor,        # Create new column names from the 'stressor' values
values_from = stress_pct,     # Fill the columns with values from the 'stress_pct'
)
stressor_wide
# Chunk 16
library("tidymodels")
library("superheat")
k <- 10  #set 10 centorids
#Apply kmean on stressor wide
kclust <- stressor_wide %>%
select(-year, -months, -state) %>%  #filter out non-numeric columns
kmeans(centers = k)
# creates column ".cluster" with cluster label
stressor_wide <- augment(kclust, stressor_wide)
# Extract centroids after tidy kclust
centroids <- tidy(kclust) %>% select(1:6, cluster)
# Pivot the centroids longer for  data preparation
long_centroids <- centroids %>%
pivot_longer(cols = -cluster, names_to = "Attribute", values_to = "Value")
# Use ggplot2 to create the bar plot
ggplot(long_centroids, aes(x = factor(cluster), y = Value, fill = Attribute)) +
geom_bar(stat = "identity", position = position_dodge()) +
theme_minimal() +
labs(x = "Cluster", y = "Value", fill = "Attribute")
# Chunk 17
#sort stressor wide based on their cluster and select only times, state and .cluster
stressor_wide <- stressor_wide %>%
select(year, months, state, .cluster)
# Create a 'time' variable by pasting 'year' and 'months' together
stressor_wide <- stressor_wide %>%
mutate(time = paste(year, months)) %>%
mutate(time = factor(time, levels = unique(time))) # Convert to a factor to maintain order
# Plot .cluster by time for each state, with facets for each state
ggplot(stressor_wide, aes(x = time, y = .cluster)) +
geom_point(aes(col = state)) +
facet_wrap(~ state, ncol = 10) + # Facets by state
theme_minimal() +
labs(x = "Time", y = "Cluster", title = "Cluster Memberships Over Time") +
theme(
axis.text.x = element_blank(), # Hide y axis text, time too long
legend.position = "none", #Hide color legend
axis.text.y = element_text(size = 5), #modify size for repel
plot.title = element_text(hjust = 0.5), # Center the plot title
)
# Chunk 18
library(shiny)
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot")
)
server <- function(input, output) {
#Answer of question a starts here:
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
}
# Chunk 19
library(shiny)
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot"),
dataTableOutput("table")
)
server <- function(input, output) {
#Answer of question b starts here:
# Reactive expression to filter data based on selected sports
filtered_data <- reactive({
if (length(input$dropdown) == 0) {
olympics$selected <- FALSE
} else {
olympics$selected <- olympics$Sport %in% input$dropdown
}
olympics
})
# Render the scatterplot based on filtered data
output$scatterplot <- renderPlot({
scatterplot(filtered_data())
})
# Render the data table for selected athletes
output$table <- renderDataTable({
filtered_data() %>%
filter(selected == TRUE) %>%
select(Name, Sport, `Height, cm`, Weight)
})
}
# Chunk 1
#Hide unnecessary output and warning message such as library(tidyverse)
knitr::opts_chunk$set(warnings = FALSE, message = FALSE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(sf)
library(raster)
library(tmap)
# Chunk 2
bike_data <- read_csv("https://uwmadison.box.com/shared/static/f16jmkkskylfl1hnd5rpslzduja929g2.csv")
head(bike_data)
# Chunk 3
#Select required data and rename them properly
q1 <- bike_data %>%
dplyr::select(weekday, hr, count) %>%
mutate(weekday = factor(weekday, levels = 0:6, labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>%
group_by(hr, weekday) %>%
summarise(summary = sum(count))
# Plotting with geom_line
ggplot(q1, aes(x = hr, y = summary)) + # Ensure that we group by weekday for the line plot
geom_line(aes(color = weekday)) +
facet_wrap(~weekday) + # Facets for each weekday
labs(x = "Hour of the Day", y = "Count of Bike Rentals", title = "Bike Demand by Hour Across the Week") +
theme_minimal()+
theme(plot.title = element_text(hjust = 0.5)) # Center the title
# Chunk 4
q2 <- bike_data %>%
mutate(yr = yr + 2011) %>%
mutate(weekday = factor(weekday, levels = 0:6, labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>%
group_by(yr, weekday, hr) %>%
summarise(
Q25 = quantile(count, 0.25),
Q75 = quantile(count, 0.75)
) %>%
rename(year = yr, hour = hr) # Renaming the columns
q2
# Chunk 5
# Merge the summary data with the quantile data.
# Since q2 contains summaries for each year, we will need to join this with q1 based on hr and weekday.
# Assuming that q1 has been grouped and summarised without the year, we will need to account for this.
# First, let's correct the renaming issue in the q2 data frame:
q1 <- q1 %>%
rename(hour = hr) # Rename hr to hour
# Now let's merge q1 and q2
q3 <- q1 %>%
ungroup() %>% # Make sure q1 is not grouped
left_join(q2, by = c("weekday", "hour")) # Join q2 data to q1 data
# Plotting with geom_ribbon and geom_line
ggplot(q3, aes(x = hour, y = summary)) +
geom_ribbon(aes(ymin = Q25, ymax = Q75, fill = as.factor(year)), alpha = 0.8) +
geom_line(aes(color = weekday)) +
facet_wrap(~weekday) + # Facets for each weekday
scale_fill_manual(values = c("blue", "red"), name = "Year") + # Set manual colors for the ribbon based on year
labs(x = "Hour of the Day", y = "Count of Bike Rentals", title = "Bike Demand by Hour Across the Week") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5)) # Center the title and move legend to bottom
# Chunk 6
nyc_sf <-read_sf("https://uwmadison.box.com/shared/static/qfmrp9srsoq0a7oj0e7xmgu5spojr33e.geojson")
nyc_sf %>%dplyr::select(geometry)
# Chunk 7
africa_pop <- raster("https://github.com/krisrs1128/stat436_s24/raw/main/data/afripop2020.tif")
africa_pop
# Chunk 8
himalayan_lakes <- read_sf("https://raw.githubusercontent.com/krisrs1128/stat436_s23/main/data/GL_3basins_2015.topojson")
himalayan_lakes %>% dplyr::select(geometry)
# Chunk 9
wi_ev_charging <- read_sf("https://raw.githubusercontent.com/krisrs1128/stat436_s24/main/data/ev.geojson")
wi_ev_charging %>% dplyr::select(geometry)
# Chunk 10
zion_evl <- raster("https://github.com/krisrs1128/stat436_s24/raw/main/data/landsat.tif")
zion_evl
# Chunk 11
tm_shape(zion_evl) +
tm_raster()
# Chunk 12
library(tidygraph)
edge_data_path <- "https://raw.githubusercontent.com/krisrs1128/stat992_f23/6c4130bddbdfc9ef90537c794cdca47773643752/activities/week10/political-books-edges.csv"
node_data_path <- "https://github.com/krisrs1128/stat992_f23/raw/6c4130bddbdfc9ef90537c794cdca47773643752/activities/week10/political-books-nodes.csv"
edges <- read_csv(edge_data_path, col_types = "cci")
nodes <- read_csv(node_data_path, col_types = "ccc")
# Building the tbl_graph
book_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)
book_graph
# Chunk 13
library(ggraph)
ggraph(book_graph, layout = "kk") +
geom_edge_link(width = 0.1) +
geom_node_point(aes(color = political_ideology))+
geom_node_label(aes(label = label), size = 1.1, repel = TRUE)
# Chunk 14
ggraph(book_graph, "matrix") +
geom_edge_tile(mirror = TRUE) + #its not directed so mirror, its ok not mirror as well
coord_fixed() #make sure grid are square
# Chunk 15
stressor <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/stressor.csv') %>%
mutate(stress_pct = replace_na(stress_pct, 0))
# Reshape the data to have stressor types as columns
stressor_wide <- stressor %>%
pivot_wider(
names_from = stressor,        # Create new column names from the 'stressor' values
values_from = stress_pct,     # Fill the columns with values from the 'stress_pct'
)
stressor_wide
# Chunk 16
library("tidymodels")
library("superheat")
k <- 10  #set 10 centorids
#Apply kmean on stressor wide
kclust <- stressor_wide %>%
select(-year, -months, -state) %>%  #filter out non-numeric columns
kmeans(centers = k)
# creates column ".cluster" with cluster label
stressor_wide <- augment(kclust, stressor_wide)
# Extract centroids after tidy kclust
centroids <- tidy(kclust) %>% select(1:6, cluster)
# Pivot the centroids longer for  data preparation
long_centroids <- centroids %>%
pivot_longer(cols = -cluster, names_to = "Attribute", values_to = "Value")
# Use ggplot2 to create the bar plot
ggplot(long_centroids, aes(x = factor(cluster), y = Value, fill = Attribute)) +
geom_bar(stat = "identity", position = position_dodge()) +
theme_minimal() +
labs(x = "Cluster", y = "Value", fill = "Attribute")
# Chunk 17
#sort stressor wide based on their cluster and select only times, state and .cluster
stressor_wide <- stressor_wide %>%
select(year, months, state, .cluster)
# Create a 'time' variable by pasting 'year' and 'months' together
stressor_wide <- stressor_wide %>%
mutate(time = paste(year, months)) %>%
mutate(time = factor(time, levels = unique(time))) # Convert to a factor to maintain order
# Plot .cluster by time for each state, with facets for each state
ggplot(stressor_wide, aes(x = time, y = .cluster)) +
geom_point(aes(col = state)) +
facet_wrap(~ state, ncol = 10) + # Facets by state
theme_minimal() +
labs(x = "Time", y = "Cluster", title = "Cluster Memberships Over Time") +
theme(
axis.text.x = element_blank(), # Hide y axis text, time too long
legend.position = "none", #Hide color legend
axis.text.y = element_text(size = 5), #modify size for repel
plot.title = element_text(hjust = 0.5), # Center the plot title
)
# Chunk 18
library(tidyverse)
olympics <- read_csv("https://uwmadison.box.com/shared/static/rzw8h2x6dp5693gdbpgxaf2koqijo12l.csv")
#' Scatterplot with highlighted points
#'
#' Assumes a column in df called "selected" saying whether points should be
#' larger / darker
scatterplot <- function(df) {
ggplot(df) +
geom_point(aes(Weight, `Height, cm`,alpha = as.numeric(selected),size = as.numeric(selected))) +
scale_alpha(range = c(0.05, .8)) +
scale_size(range = c(0.1, 1))
}
ui <- fluidPage(
selectInput("dropdown", "Select a Sport", choices = unique(olympics$Sport), multiple = TRUE),
plotOutput("scatterplot")
)
